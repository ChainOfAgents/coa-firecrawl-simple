steps:
  # Build the API image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'gcr.io/${PROJECT_ID}/crawlweb-api:${COMMIT_SHA}', '-t', 'gcr.io/${PROJECT_ID}/crawlweb-api:latest', '-f', 'Dockerfile', './apps/api']
    
  # Push the container image to Container Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'gcr.io/${PROJECT_ID}/crawlweb-api:${COMMIT_SHA}']
    
  # Get Redis IP and Puppeteer URL, then deploy API to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args: 
      - '-c'
      - |
        # Get Redis IP
        REDIS_IP=$(gcloud redis instances describe crawlweb-redis --region=us-west2 --format='get(host)')
        
        # Get Puppeteer Service URL from Cloud Storage (or use fallback)
        gsutil cp gs://${PROJECT_ID}-build-artifacts/puppeteer-service-url.txt /workspace/ 2>/dev/null || echo "https://puppeteer-service-url-not-found.run.app/scrape" > /workspace/puppeteer-service-url.txt
        PLAYWRIGHT_URL=$(cat /workspace/puppeteer-service-url.txt)
        
        # Deploy API to Cloud Run
        gcloud run deploy crawlweb-api \
          --image=gcr.io/${PROJECT_ID}/crawlweb-api:${COMMIT_SHA} \
          --platform=managed \
          --region=us-west2 \
          --cpu=1 \
          --memory=1Gi \
          --concurrency=80 \
          --command="pnpm,run,start:production" \
          --vpc-connector=crawlweb-connector \
          --allow-unauthenticated \
          --min-instances=0 \
          --max-instances=10 \
          --set-env-vars="NUM_WORKERS_PER_QUEUE=8,PORT=8080,HOST=0.0.0.0,REDIS_URL=redis://$${REDIS_IP}:6379,REDIS_RATE_LIMIT_URL=redis://$${REDIS_IP}:6379,PLAYWRIGHT_MICROSERVICE_URL=$${PLAYWRIGHT_URL}"

images:
  - 'gcr.io/${PROJECT_ID}/crawlweb-api:${COMMIT_SHA}'
  - 'gcr.io/${PROJECT_ID}/crawlweb-api:latest'

options:
  logging: CLOUD_LOGGING_ONLY
